{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# IMPORTANT: In the top right corner, click “Connect” and wait until it shows that it is connected with a green checkmark. Once connected, run each code cell by clicking the Play button in the top left of the cell or by pressing Shift + Enter. Be sure to run the cells in order from top to bottom so that all variables and libraries are properly loaded before later code executes.\n",
    "\n",
    "\n",
    "# Dura Bulk Detector\n",
    "Scrape Instagram images by hashtag, detect boats with YOLOv8, OCR for \"Dura Bulk\" text, and sort results into Google Drive.\n",
    "\n",
    "**Output folders in Google Drive:**\n",
    "- `Dura Bulk/Boat/` — images with \"Dura Bulk\" text on boats\n",
    "- `Dura Bulk/Other/` — all other images\n",
    "\n",
    "## 1. Install Dependencies"
   ],
   "metadata": {
    "id": "yswjmSUjgiQC"
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BSWH9H9nxr8n",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "53a6ac66-99c3-475a-afd5-86e9bf9d3544"
   },
   "outputs": [],
   "source": "!pip install -q apify-client ultralytics easyocr pillow"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 2. Mount Google Drive"
   ],
   "metadata": {
    "id": "gb6ErjSEgq9t"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import os\n",
    "BOAT_DIR = '/content/drive/MyDrive/Dura Bulk/Boat'\n",
    "OTHER_DIR = '/content/drive/MyDrive/Dura Bulk/Other'\n",
    "os.makedirs(BOAT_DIR, exist_ok=True)\n",
    "os.makedirs(OTHER_DIR, exist_ok=True)\n",
    "print(f'Boat folder:  {BOAT_DIR}')\n",
    "print(f'Other folder: {OTHER_DIR}')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HB3cJ8AlgpUK",
    "outputId": "e10022b3-4c18-4459-f0e5-e694fc66769c"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n",
      "Boat folder:  /content/drive/MyDrive/Dura Bulk/Boat\n",
      "Other folder: /content/drive/MyDrive/Dura Bulk/Other\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cf82de40"
   },
   "source": "## 3. Settings\nEnter your hashtag and date range below!\n\n### Instagram Login (Session File)\nInstagram blocks direct username/password login from scripts. You must create a **session file** first:\n\n1. **On your local computer** (not in Colab), open a terminal and run:\n   ```\n   pip install instaloader\n   instaloader --login YOUR_USERNAME\n   ```\n   It will ask for your password (and possibly a 2FA code). This creates a session file at:\n   - **Mac/Linux:** `~/.config/instaloader/session-YOUR_USERNAME`\n   - **Windows:** `%LOCALAPPDATA%\\instaloader\\session-YOUR_USERNAME`\n\n2. **Upload the session file** to Colab when prompted in the next cell.\n\n**Tip:** Use a throwaway Instagram account for this."
  },
  {
   "cell_type": "code",
   "source": "#@title Pipeline Settings { run: \"auto\" }\nHASHTAG = \"santacruzdetenerife\" #@param {type:\"string\"}\nSTART_DATE = \"2025-08-20\" #@param {type:\"date\"}\nEND_DATE = \"2025-10-01\" # @param {\"type\":\"date\",\"placeholder\":\"31-01-2025\"}\nMAX_POSTS = 100 #@param {type:\"slider\", min:10, max:500, step:10}\n\n# Instagram username (must match the session file you created locally)\nINSTA_USERNAME = \"\" #@param {type:\"string\"}\n\nprint(f'Will scrape #{HASHTAG} from {START_DATE} to {END_DATE} (max {MAX_POSTS} posts)')\nif INSTA_USERNAME:\n    print(f'Will load session for @{INSTA_USERNAME}')\nelse:\n    print('⚠️  No username set — fill in INSTA_USERNAME above')",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9BbFzjao1tSe",
    "outputId": "f9e69962-3379-42fd-b63e-956f235c2e41",
    "cellView": "form"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "## 3b. Upload Session File\nRun this cell to upload the session file you created on your local machine.",
   "metadata": {
    "id": "nuyYMvKb-wOK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": "import tempfile\nfrom datetime import datetime\nfrom pathlib import Path\nimport instaloader\n\nTMP_DIR = tempfile.mkdtemp(prefix='dura_bulk_')\n\nL = instaloader.Instaloader(\n    dirname_pattern=TMP_DIR,\n    download_videos=False,\n    download_video_thumbnails=False,\n    download_geotags=False,\n    download_comments=False,\n    save_metadata=False,\n    post_metadata_txt_pattern='',\n)\n\n# Load session file (created locally with: instaloader --login USERNAME)\nif INSTA_USERNAME:\n    try:\n        L.load_session_from_file(INSTA_USERNAME)\n        print(f'Loaded session for @{INSTA_USERNAME}')\n    except FileNotFoundError:\n        print('Session file not found! Make sure you uploaded it in the previous step.')\n        raise\nelse:\n    print('No username set — scraping without login (will likely fail)')\n\nstart_dt = datetime.strptime(START_DATE, '%Y-%m-%d')\nend_dt = datetime.strptime(END_DATE, '%Y-%m-%d')\n\nprint(f'Scraping #{HASHTAG}...')\ncount = 0\ntry:\n    posts = instaloader.Hashtag.from_name(L.context, HASHTAG).get_posts()\n    for post in posts:\n        if count >= MAX_POSTS:\n            break\n        post_date = post.date_local\n        if post_date.date() > end_dt.date():\n            continue\n        if post_date.date() < start_dt.date():\n            break\n        try:\n            L.download_post(post, target='')\n            count += 1\n            if count % 5 == 0:\n                print(f'  Downloaded {count} posts...')\n        except Exception as e:\n            print(f'  Skipped post: {e}')\n            continue\nexcept Exception as e:\n    print(f'Scrape error: {e}')\n\nimage_paths = [\n    f for f in Path(TMP_DIR).rglob('*')\n    if f.suffix.lower() in ('.jpg', '.jpeg', '.png', '.webp')\n]\nprint(f'\\nDone! Downloaded {len(image_paths)} images from {count} posts')",
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "22d9e829",
    "outputId": "a67e2636-9d72-424f-db8c-2b7644e40864"
   },
   "source": [
    "import tempfile\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "import instaloader\n",
    "\n",
    "TMP_DIR = tempfile.mkdtemp(prefix='dura_bulk_')\n",
    "\n",
    "L = instaloader.Instaloader(\n",
    "    dirname_pattern=TMP_DIR,\n",
    "    download_videos=False,\n",
    "    download_video_thumbnails=False,\n",
    "    download_geotags=False,\n",
    "    download_comments=False,\n",
    "    save_metadata=False,\n",
    "    post_metadata_txt_pattern='',\n",
    ")\n",
    "\n",
    "if INSTA_USERNAME and INSTA_PASSWORD:\n",
    "    try:\n",
    "        L.login(INSTA_USERNAME, INSTA_PASSWORD)\n",
    "        print('Logged in to Instagram')\n",
    "    except Exception as e:\n",
    "        print(f'Login failed (continuing without login): {e}')\n",
    "\n",
    "start_dt = datetime.strptime(START_DATE, '%Y-%m-%d')\n",
    "end_dt = datetime.strptime(END_DATE, '%Y-%m-%d')\n",
    "\n",
    "print(f'Scraping #{HASHTAG}...')\n",
    "count = 0\n",
    "try:\n",
    "    posts = instaloader.Hashtag.from_name(L.context, HASHTAG).get_posts()\n",
    "    for post in posts:\n",
    "        if count >= MAX_POSTS:\n",
    "            break\n",
    "        post_date = post.date_local\n",
    "        if post_date.date() > end_dt.date():\n",
    "            continue\n",
    "        if post_date.date() < start_dt.date():\n",
    "            break\n",
    "        try:\n",
    "            L.download_post(post, target='')\n",
    "            count += 1\n",
    "            if count % 5 == 0:\n",
    "                print(f'  Downloaded {count} posts...')\n",
    "        except Exception as e:\n",
    "            print(f'  Skipped post: {e}')\n",
    "            continue\n",
    "except Exception as e:\n",
    "    print(f'Scrape error: {e}')\n",
    "\n",
    "image_paths = [\n",
    "    f for f in Path(TMP_DIR).rglob('*')\n",
    "    if f.suffix.lower() in ('.jpg', '.jpeg', '.png', '.webp')\n",
    "]\n",
    "print(f'\\nDone! Downloaded {len(image_paths)} images from {count} posts')"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Login failed (continuing without login): Login error: \"fail\" status, message \"CSRF token missing or incorrect\".\n",
      "Scraping #santacruzdetenerife...\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "JSON Query to api/v1/tags/web_info/: 403 Forbidden - \"fail\" status, message \"login_required\" when accessing https://i.instagram.com/api/v1/tags/web_info/?__a=1&__d=dis&tag_name=santacruzdetenerife [retrying; skip with ^C]\n",
      "JSON Query to api/v1/tags/web_info/: 403 Forbidden - \"fail\" status, message \"login_required\" when accessing https://i.instagram.com/api/v1/tags/web_info/?__a=1&__d=dis&tag_name=santacruzdetenerife [retrying; skip with ^C]\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scrape error: JSON Query to api/v1/tags/web_info/: 403 Forbidden - \"fail\" status, message \"login_required\" when accessing https://i.instagram.com/api/v1/tags/web_info/?__a=1&__d=dis&tag_name=santacruzdetenerife\n",
      "\n",
      "Done! Downloaded 0 images from 0 posts\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 4b. (Alternative) Upload images manually\n",
    "If scraping doesn't work or you already have images, upload them here instead."
   ],
   "metadata": {
    "id": "gLV5HmN3g4Nt"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# Uncomment and run this cell to upload images manually instead of scraping\n",
    "\n",
    "# from google.colab import files\n",
    "# import tempfile\n",
    "# from pathlib import Path\n",
    "#\n",
    "# TMP_DIR = tempfile.mkdtemp(prefix='dura_bulk_upload_')\n",
    "# uploaded = files.upload()\n",
    "# for name, data in uploaded.items():\n",
    "#     with open(os.path.join(TMP_DIR, name), 'wb') as f:\n",
    "#         f.write(data)\n",
    "#\n",
    "# image_paths = [\n",
    "#     f for f in Path(TMP_DIR).rglob('*')\n",
    "#     if f.suffix.lower() in ('.jpg', '.jpeg', '.png', '.webp')\n",
    "# ]\n",
    "# print(f'Uploaded {len(image_paths)} images')"
   ],
   "metadata": {
    "id": "98VY2Jj3g41F"
   },
   "execution_count": 6,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 5. Detect Boats + OCR for \"Dura Bulk\""
   ],
   "metadata": {
    "id": "5LNx6ceeg8f4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import shutil\n",
    "from PIL import Image\n",
    "from ultralytics import YOLO\n",
    "import easyocr\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "# Load models\n",
    "print('Loading YOLOv8 model...')\n",
    "model = YOLO('yolov8n.pt')\n",
    "print('Loading EasyOCR reader...')\n",
    "reader = easyocr.Reader(['en'], gpu=True)\n",
    "print('Models ready!\\n')\n",
    "\n",
    "\n",
    "def fuzzy_match_dura_bulk(text):\n",
    "    text = text.lower().strip()\n",
    "    if 'dura' in text and 'bulk' in text:\n",
    "        return True\n",
    "    cleaned = re.sub(r'[^a-z0-9]', '', text)\n",
    "    if 'durabulk' in cleaned:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "boat_images = []\n",
    "other_images = []\n",
    "\n",
    "for i, img_path in enumerate(image_paths):\n",
    "    print(f'[{i+1}/{len(image_paths)}] {img_path.name}', end=' ')\n",
    "\n",
    "    try:\n",
    "        img = Image.open(img_path).convert('RGB')\n",
    "    except Exception:\n",
    "        print('- skipped (can\\'t open)')\n",
    "        continue\n",
    "\n",
    "    results = model(img, verbose=False)\n",
    "    is_dura = False\n",
    "\n",
    "    boat_count = 0\n",
    "    for result in results:\n",
    "        for box in result.boxes:\n",
    "            cls_id = int(box.cls[0])\n",
    "            if cls_id != 8:  # 8 = boat in COCO\n",
    "                continue\n",
    "            boat_count += 1\n",
    "\n",
    "            x1, y1, x2, y2 = map(int, box.xyxy[0].tolist())\n",
    "            crop = img.crop((x1, y1, x2, y2))\n",
    "\n",
    "            crop_path = str(img_path) + '_crop.jpg'\n",
    "            crop.save(crop_path)\n",
    "            try:\n",
    "                ocr_results = reader.readtext(crop_path)\n",
    "                all_text = ' '.join([r[1] for r in ocr_results])\n",
    "                if all_text.strip():\n",
    "                    print(f'[OCR: \"{all_text.strip()}\"]', end=' ')\n",
    "                if fuzzy_match_dura_bulk(all_text):\n",
    "                    is_dura = True\n",
    "                    break\n",
    "            except Exception:\n",
    "                pass\n",
    "            finally:\n",
    "                if os.path.exists(crop_path):\n",
    "                    os.remove(crop_path)\n",
    "\n",
    "        if is_dura:\n",
    "            break\n",
    "\n",
    "    # Sort into Google Drive folders\n",
    "    dest_name = f'{HASHTAG}_{i:04d}{img_path.suffix}'\n",
    "    if is_dura:\n",
    "        shutil.copy2(img_path, os.path.join(BOAT_DIR, dest_name))\n",
    "        boat_images.append(dest_name)\n",
    "        print(f'-> DURA BULK (boat detected, text matched)')\n",
    "    else:\n",
    "        shutil.copy2(img_path, os.path.join(OTHER_DIR, dest_name))\n",
    "        other_images.append(dest_name)\n",
    "        if boat_count > 0:\n",
    "            print(f'-> Other ({boat_count} boat(s), no match)')\n",
    "        else:\n",
    "            print(f'-> Other (no boats detected)')\n",
    "\n",
    "# Cleanup\n",
    "shutil.rmtree(TMP_DIR, ignore_errors=True)\n",
    "\n",
    "print(f'\\n{\"=\"*50}')\n",
    "print(f'RESULTS')\n",
    "print(f'{\"=\"*50}')\n",
    "print(f'Dura Bulk (Boat folder): {len(boat_images)} images')\n",
    "print(f'Other:                   {len(other_images)} images')\n",
    "print(f'Total processed:         {len(boat_images) + len(other_images)} images')\n",
    "print(f'\\nFiles saved to Google Drive:')\n",
    "print(f'  {BOAT_DIR}')\n",
    "print(f'  {OTHER_DIR}')"
   ],
   "metadata": {
    "id": "7NXZ_NJug7_Q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "47c2d984-6653-42eb-ea39-df956e831a11"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
      "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
      "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 6. Preview Results"
   ],
   "metadata": {
    "id": "drIWz3_Jg-f6"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "def show_gallery(folder, title, file_list, max_show=12):\n",
    "    files = file_list[:max_show]\n",
    "    if not files:\n",
    "        print(f'{title}: no images')\n",
    "        return\n",
    "\n",
    "    cols = min(4, len(files))\n",
    "    rows = (len(files) + cols - 1) // cols\n",
    "    fig, axes = plt.subplots(rows, cols, figsize=(4*cols, 4*rows))\n",
    "    fig.suptitle(f'{title} ({len(file_list)} total)', fontsize=16, fontweight='bold')\n",
    "\n",
    "    if rows == 1 and cols == 1:\n",
    "        axes = [[axes]]\n",
    "    elif rows == 1:\n",
    "        axes = [axes]\n",
    "    elif cols == 1:\n",
    "        axes = [[ax] for ax in axes]\n",
    "\n",
    "    for idx, name in enumerate(files):\n",
    "        r, c = divmod(idx, cols)\n",
    "        ax = axes[r][c]\n",
    "        try:\n",
    "            img = mpimg.imread(os.path.join(folder, name))\n",
    "            ax.imshow(img)\n",
    "        except Exception:\n",
    "            pass\n",
    "        ax.set_title(name, fontsize=8)\n",
    "        ax.axis('off')\n",
    "\n",
    "    # Hide empty subplots\n",
    "    for idx in range(len(files), rows * cols):\n",
    "        r, c = divmod(idx, cols)\n",
    "        axes[r][c].axis('off')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_gallery(BOAT_DIR, 'Dura Bulk (Boat)', boat_images)\n",
    "show_gallery(OTHER_DIR, 'Other', other_images)"
   ],
   "metadata": {
    "id": "1Fcn8I2khA1H"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}